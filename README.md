# Timbre Space EQ

Musical expectation and structural tension play a fundamental role in how listeners perceive, anticipate, and emotionally respond to music. Despite their importance, these phenomena are typically treated as latent cognitive processes that can only be inferred indirectly through behavioral experiments or offline analytical methods. Existing music analysis tools often separate harmony and timbre, rely on symbolic representations, or operate as opaque computational models that obscure perceptually meaningful structure. This paper presents a real-time analytical system that makes musical expectation observable by jointly visualizing timbral motion and harmonic predictability within a shared perceptual space. The system employs interpretable FFT-based timbral features and a first-order Markov model of chord transitions to externalize moment-to-moment dynamics of anticipation, tension, and release as music unfolds. In addition, the system produces structured, time-aligned representations of timbral trajectories and harmonic context that can be exported as datasets. These representations provide a foundation for future machine learning research by capturing perceptually meaningful timbral structure that is largely absent from existing generative music training data. The system thus functions both as a research instrument for music perception and cognition and as a data-generation framework for future computational modeling of musical structure.
